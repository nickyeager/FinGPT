{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-27 11:06:37,334 | INFO : Hello world!\n"
     ]
    }
   ],
   "source": [
    "#  import pkg_resources\n",
    "#  import pip\n",
    "#  installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "#  required = { 'openai','datasets', 'sklearn', 'tqdm'}\n",
    "#  missing = required - installedPackages\n",
    "# if missing:\n",
    "#         !pip install openai\n",
    "#         !pip install datasets\n",
    "#         !pip install scikit-learn\n",
    "#         !pip install tqdm\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "logging.info('Hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-37320c388885>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mopenai\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mdatasets\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0maccuracy_score\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf1_score\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mconfusion_matrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score,confusion_matrix\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set your OpenAI API key\n",
    "openai.api_key='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset and add prompt\n",
    "def get_dataset(n_limit=0):\n",
    "    dataset=load_dataset('financial_phrasebank','sentences_50agree')\n",
    "    \n",
    "    dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "    dataset = dataset[\"test\"]\n",
    "    print(dataset)\n",
    "    if n_limit>0:\n",
    "        dataset['train']=dataset['train'][:n_limit]\n",
    "    print(\"size of dataset: \", len( dataset['train']['sentence']))\n",
    "    text_inputs = dataset['train']['sentence']\n",
    "    process_inputs=[\n",
    "        f\"Human: Determine the sentiment of the financial news as negative, neutral or positive: {text_inputs[i]} Assistant: \"\n",
    "        for i in range(len(text_inputs))]\n",
    "    labels=dataset['train']['label']\n",
    "    return process_inputs, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatGPT API\n",
    "def chat_with_gpt(prompt):\n",
    "    response=openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[\n",
    "            {\"role\":\"system\", \"content\":\"Hello\"},\n",
    "            {\"role\": \"user\",\"content\":prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 970\n",
      "})\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column train not in the dataset. Current columns in the dataset: ['sentence', 'label']\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sentences, labels \u001B[39m=\u001B[39m get_dataset()\n",
      "Cell \u001B[0;32mIn[53], line 10\u001B[0m, in \u001B[0;36mget_dataset\u001B[0;34m(n_limit)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[39mif\u001B[39;00m n_limit\u001B[39m>\u001B[39m\u001B[39m0\u001B[39m:\n\u001B[1;32m      9\u001B[0m     dataset[\u001B[39m'\u001B[39m\u001B[39mtrain\u001B[39m\u001B[39m'\u001B[39m]\u001B[39m=\u001B[39mdataset[\u001B[39m'\u001B[39m\u001B[39mtrain\u001B[39m\u001B[39m'\u001B[39m][:n_limit]\n\u001B[0;32m---> 10\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39m\"\u001B[39m\u001B[39msize of dataset: \u001B[39m\u001B[39m\"\u001B[39m, \u001B[39mlen\u001B[39m( dataset[\u001B[39m'\u001B[39;49m\u001B[39mtrain\u001B[39;49m\u001B[39m'\u001B[39;49m][\u001B[39m'\u001B[39m\u001B[39msentence\u001B[39m\u001B[39m'\u001B[39m]))\n\u001B[1;32m     11\u001B[0m text_inputs \u001B[39m=\u001B[39m dataset[\u001B[39m'\u001B[39m\u001B[39mtrain\u001B[39m\u001B[39m'\u001B[39m][\u001B[39m'\u001B[39m\u001B[39msentence\u001B[39m\u001B[39m'\u001B[39m]\n\u001B[1;32m     12\u001B[0m process_inputs\u001B[39m=\u001B[39m[\n\u001B[1;32m     13\u001B[0m     \u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mHuman: Determine the sentiment of the financial news as negative, neutral or positive: \u001B[39m\u001B[39m{\u001B[39;00mtext_inputs[i]\u001B[39m}\u001B[39;00m\u001B[39m Assistant: \u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m     14\u001B[0m     \u001B[39mfor\u001B[39;00m i \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(\u001B[39mlen\u001B[39m(text_inputs))]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.11/lib/python3.9/site-packages/datasets/arrow_dataset.py:2803\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   2801\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__getitem__\u001B[39m(\u001B[39mself\u001B[39m, key):  \u001B[39m# noqa: F811\u001B[39;00m\n\u001B[1;32m   2802\u001B[0m \u001B[39m    \u001B[39m\u001B[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[0;32m-> 2803\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_getitem(key)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.11/lib/python3.9/site-packages/datasets/arrow_dataset.py:2787\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[0;34m(self, key, **kwargs)\u001B[0m\n\u001B[1;32m   2785\u001B[0m format_kwargs \u001B[39m=\u001B[39m format_kwargs \u001B[39mif\u001B[39;00m format_kwargs \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39melse\u001B[39;00m {}\n\u001B[1;32m   2786\u001B[0m formatter \u001B[39m=\u001B[39m get_formatter(format_type, features\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_info\u001B[39m.\u001B[39mfeatures, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mformat_kwargs)\n\u001B[0;32m-> 2787\u001B[0m pa_subtable \u001B[39m=\u001B[39m query_table(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_data, key, indices\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_indices \u001B[39mif\u001B[39;49;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_indices \u001B[39mis\u001B[39;49;00m \u001B[39mnot\u001B[39;49;00m \u001B[39mNone\u001B[39;49;00m \u001B[39melse\u001B[39;49;00m \u001B[39mNone\u001B[39;49;00m)\n\u001B[1;32m   2788\u001B[0m formatted_output \u001B[39m=\u001B[39m format_table(\n\u001B[1;32m   2789\u001B[0m     pa_subtable, key, formatter\u001B[39m=\u001B[39mformatter, format_columns\u001B[39m=\u001B[39mformat_columns, output_all_columns\u001B[39m=\u001B[39moutput_all_columns\n\u001B[1;32m   2790\u001B[0m )\n\u001B[1;32m   2791\u001B[0m \u001B[39mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.11/lib/python3.9/site-packages/datasets/formatting/formatting.py:580\u001B[0m, in \u001B[0;36mquery_table\u001B[0;34m(table, key, indices)\u001B[0m\n\u001B[1;32m    578\u001B[0m     _raise_bad_key_type(key)\n\u001B[1;32m    579\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39misinstance\u001B[39m(key, \u001B[39mstr\u001B[39m):\n\u001B[0;32m--> 580\u001B[0m     _check_valid_column_key(key, table\u001B[39m.\u001B[39;49mcolumn_names)\n\u001B[1;32m    581\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    582\u001B[0m     size \u001B[39m=\u001B[39m indices\u001B[39m.\u001B[39mnum_rows \u001B[39mif\u001B[39;00m indices \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39melse\u001B[39;00m table\u001B[39m.\u001B[39mnum_rows\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.11/lib/python3.9/site-packages/datasets/formatting/formatting.py:520\u001B[0m, in \u001B[0;36m_check_valid_column_key\u001B[0;34m(key, columns)\u001B[0m\n\u001B[1;32m    518\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_check_valid_column_key\u001B[39m(key: \u001B[39mstr\u001B[39m, columns: List[\u001B[39mstr\u001B[39m]) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m    519\u001B[0m     \u001B[39mif\u001B[39;00m key \u001B[39mnot\u001B[39;00m \u001B[39min\u001B[39;00m columns:\n\u001B[0;32m--> 520\u001B[0m         \u001B[39mraise\u001B[39;00m \u001B[39mKeyError\u001B[39;00m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mColumn \u001B[39m\u001B[39m{\u001B[39;00mkey\u001B[39m}\u001B[39;00m\u001B[39m not in the dataset. Current columns in the dataset: \u001B[39m\u001B[39m{\u001B[39;00mcolumns\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Column train not in the dataset. Current columns in the dataset: ['sentence', 'label']\""
     ]
    }
   ],
   "source": [
    "sentences, labels = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4846"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Determine the sentiment of the financial news as negative, neutral or positive: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing . Assistant: '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive: 2, negative: 0, neutral:1\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatgpt response \n",
    "preds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:12,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "#test run\n",
    "import time\n",
    "for prompt, label in tqdm(zip(sentences[0:5],labels)):\n",
    "    #print(prompt, label)\n",
    "    time.sleep(1)\n",
    "    response=chat_with_gpt(prompt)\n",
    "    if   \"negative\" in response:\n",
    "        preds.append(0)\n",
    "    elif \"neutral\" in response:\n",
    "        preds.append(1)\n",
    "    elif \"positive\" in response:\n",
    "        preds.append(2)\n",
    "    else:\n",
    "        preds.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 2, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(labels[0:5],preds[0:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8222222222222223\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1: {f1_score(labels[0:5],preds[0:5],average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bc9bc39992aa06fe899ee986997a8bcf853fd65bdbc2b3f8950285158f8c2b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}